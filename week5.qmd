---
title: "Joint treatment effects - Lab exercises"
subtitle: "DCSBS (week 7)"
author: "Jeroen D. Mulder and Ellen L. Hamaker"
format: 
  html:
    self-contained: true
    toc: true
editor: source
bibliography: references.bib
---

This lab contains two exercises, which will guide you through the three phases of causal inferences as discussed during the lectures. The first exercise covers material discussed in the first lecture (on Monday), and the second exercise covers material discussed in the second lecture (on Wednesday). However, in contrast to the lectures, you will (a) work with the empirical example in @vanderweele_causal_2016; (b) consider a more complex (and also more realistic) causal DAG, which will influence our decisions across the three phases; and (c) work with simulated data to get a better understanding of what joint effects are, and how inverse probability weighting estimation works. 

This week is also the start of the second graded group assignment. You can find the assignment on Blackboard. Please make sure that by the end of the first lab, you have read the assignment. That way, you have the opportunity to ask to lab teachers for clarification if anything is unclear. 

# Phase I: Formulation
@vanderweele_causal_2016 use an empirical example to illustrate the use of marginal structural models (MSMs) and inverse-probability-weighting (IPW) estimation. Read the section ``Results: empirical illustrations'', and answer the below questions. Additionally, look up the empirical study upon which this example is based; You need this study to find answers to some of the questions. Finally, and perhaps most importantly, challenge yourself. Really try to come up with a comprehensive answer to the questions before you look at the answers. That way, you test if you truly grasp the contents, and whether or not you can apply it to new problems. These are also the skills that will be tested on the exam. 

1. Formulate the causal research question of @vanderweele_causal_2016 in words. In your answer, specify the target population, the exposures, the exposure contrast, and the outcome measure. Do @vanderweele_causal_2016 focus on specific regimes? 

::: {.callout-note collapse="true" icon=false}
### Answer 1

Generally speaking, @vanderweele_causal_2016 investigate the bidirectional relationship between religious service attendance and depression. More specifically, they assess the joint effect of religious service attendance in 1996 and in 2000 on depression in 2004; and the joint effect of depression in 1996 and 2000 on religious service attendance in 2004. For the rest of this exercise, we focus on religious service attendance as the exposure, and depression as the outcome. More information can be found in the study by @li_religious_2016. 

Both @vanderweele_causal_2016 and @li_religious_2016 are implicit about the target population. Based on their sample, it can be inferred that their target population is female nurses across the United States. @li_religious_2016 states: "We, therefore, considered analyses both with and without participants who had a diagnosis of cardiovascular disease or cancer at baseline (n=19,803)". They thus considered restricting their target population to only those without diagnosis of cardiovascular disease or cancer. Later, @li_religious_2016 describes how the analyses are repeated, but restricted to either only Catholics or Protestants, thereby further specifying a specific target population. 

The outcome, depression, was defined as ``(...) either self-reported physician or clinician-diagnosed depression, or use of antidepressant medications, or depressive symptoms CESD-10 measure above 10.''. The CESD-10 is a 10-item Likert scale screening questionnaire assessing depressive symptoms *in the past week*. It was measured in 2004, that is eight years after the first exposure-measurement (in 1996), and four years after the second exposure-measurement (in 2000). 

The exposure was self-reported service attendance using the question: "How often in the past year do you attend religious services?" Answer categories were "More than once per week", "Once per week", "Less than once per week", and "Never or almost never". 

@vanderweele_causal_2016 and @li_religious_2016 do not express interest in any particular exposure regime. Therefore, there is also no explicit exposure contrast.
:::

2. Is this research question about an ACE, ACE$_{1}$, or ACE$_{0}$? Reformulate the research question for those ACE$_{...}$'s left over. 

::: {.callout-note collapse="true" icon=false}
### Answer 2

@li_religious_2016 research targets an average causal effect (ACE). A related ACE$_{1}$ could be: "Should psychologists discourage going to religious services for those female nurses in the US that currently do attend religious services?" A related ACE$_{0}$ could be: "Should psychologists encourage going to religious services at least once a week among those female nurses in the US that currently do not frequent religious services?"
:::

3. Formulate the marginal structural model that is used. Tip: Consider how many times the exposure was measured, and the measurement level of the exposure and outcome; see Table 2 in @vanderweele_causal_2016.  

::: {.callout-note collapse="true" icon=false}
### Answer 3

The outcome is binary, and thus we need to specify a *logistic* marginal structural model. The exposures are categorical, containing four categories, and there are two time points at which exposures were measured. Based on this, we can infer which MSM was likely specified:
$$
logit \; Pr[Y^{\{A_{1}, A_{2}\}}] = \gamma_{0} + \gamma_{1} A_{1, C2} + \gamma_{2} A_{1, C3} + \gamma_{3} A_{1,C4} + \gamma_{4} A_{2, C2} + \gamma_{5} A_{2, C3} + \gamma_{6} A_{2, C4} + ...
$$
The $logit$ was used here because we are dealing with dichotomous outcome. Table 2 in @vanderweele_causal_2016 states that the exposure category "Never" is the reference category. Therefore, $A_{1, C2}$, $A_{1, C3}$, and $A_{1, C4}$ are dummy variables for the religious service attendance categories "< 1/week" (category 2), "1/week" (category 3), and "< 1/week" (category 4) *in 1996*, respectively. $A_{2, C2}$, $A_{2, C3}$, and $A_{2, C4}$ are dummy variables for the religious service attendance categories "< 1/week", "1/week", and "<1/week" *in 2000*, respectively. $exp(\gamma_{...})$ then represent causal odds ratios. For example, $exp(\gamma_{1})$ is the causal odds ratio of depression in 2004 for religious service attendance less than once a week in 1996 versus never religious service attendance in 1996. The term $+ ...$ in the MSM above represents the uncertainty around whether or not @vanderweele_causal_2016 additionally included baseline covariates in the MSM. Their SAS and STATA code in the online supplementary materials suggest that they did, but this is not clear from the main article. 
:::

4. Is this a saturated MSM? If yes, what is the advantage/disadvantage of a saturated MSM? If no, what is the advantage/disadvantage of an unsaturated MSM? Tip: Think about the expected potential outcomes that exist, and compare this to the number of parameters in the MSM. 

::: {.callout-note collapse="true" icon=false}
### Answer 4

A saturated MSM has as many parameters as there are potential outcome expectations. In this case, a selection of potential outcome expectations are:

- $Y^{\{0, 0\}}$, representing never attending religious service in 1996 and 2000.
- $Y^{\{1, 0\}}$, representing attending religious services < 1/week in 1996, and never in 2000. 
- $Y^{\{2, 0\}}$, representing attending religious services 1/week in 1996, and never in 2000.
- etc.

In total, there are 16 exposure regimes, and therefore 16 potential outcome expectations. The MSM, however, contains 7 parameters. Therefore, the MSM is nonsaturated, and encodes some causal assumptions. Which assumptions are encoded in this MSM? How can this MSM be adjusted to make it satured? 

The reason why, especially in settings with many repeated measures or with a continuous exposure, we need to work with nonsaturated MSMs is because there simply exist to many potential outcome expectations. For example, with a binary exposure and $k$ number of repeated measures, there exist $2^{k}$ number or potential outcome expectations, meaning that with 10 repeated measures, we would need to specify an MSM with $2^{10} = 1024$ parameters. 

The disadvantage is that nonsaturated models make assumptions which, when violated, bias our effects of interest. For the MSM from @vanderweele_causal_2016, we assume that the direct effect of religious service attendance in 2000 is not dependent on an individuals religious service attendance in 1996. 
:::

# Phases II and III: Identification and estimation
In this exercise, you will gain experience with IPW estimation using simulated data. For this, we will leave the empirical example in @vanderweele_causal_2016 be. We will investigate the joint effect of a time-varying binary exposure (measured at three occasions) on a continuous distal outcome. Examples of this are the joint effect of

- church attendance on depressive symptoms (measured continuously, rather than dichotomously as in the empirical example);
- Ritalin use or physical punishment (by the parents) on behavioral problems (of the child);
- establishing a gender quota in a company on the percentage of women working there; and
- drug use on academic achievement in adolescents. 

In all these cases, the exposure is a binary variable that may vary over time, and that may affect the final outcome at the end of the study directly or indirectly through shaping earlier realizations of the outcome variable. 

## Structural relations (truth)

1. Consider the code provided here, and draw the causal DAG that is associated with it. 

```{r data-generation, echo=T, eval=T, message=F, include=T}
N <- 1000000
C <- rnorm(N)

data <- data.frame(C)

# Simulate data for first wave
data$Y1 <- .4*C + rnorm(N)
data$X1 <- rbinom(n = N, size=1, prob = plogis(C))

# Simulate data for the second wave
data$Y2 <- 0.1 * data$Y1 + 0.3 * data$X1 + rnorm(N)
data$X2 <- rbinom(n = N, size=1, prob = 
		plogis(-.8 + 0.2 * data$Y1 + 1 * data$X1))

# Simulate data for the third wave
data$Y3 <- 0.1 * data$Y2 + 0.3 * data$X2 + 
		0.8 * data$Y1 + 0.15 * data$X1 + rnorm(N)
data$X3 <- rbinom(n = N, size=1, prob = 
		plogis(-.8 + 0.2 * data$Y2 + 1 * data$X2 +
			0.1 * data$Y1 + 0.8 * data$X1))

# Simulate the final outcome
data$final.Y <- 0.1 * data$Y3 + 0.3 * data$X3 + 0.8 * data$Y2 + 
			0.15 * data$X2 + rnorm(N)

# Check the data file
head(data)
```

::: {.callout-note collapse="true" icon=false}
### Answer 1: Causal DAG

![Causal DAG based on the R code.](./figures/causalDAG.jpeg) 

This figure does not depict linear or logistic regressions per se, but instead visualizes the causal (structural) relations between the variables. However, since we generated the data ourselves, we know that these relationships are in fact linear and logistic. 
:::

2. Indicate which causal paths there are from $X_{1}$ to $Y_{4}$ and that do not go through later exposures. Based on the population parameter values in the R code to generate the data, compute what the true controlled direct effect is of $X_{1}$ on $Y_{4}$.

::: {.callout-note collapse="true" icon=false}
### Answer 2: True CDE $X_{1} \rightarrow Y_{4}$

```{r CDE1-population, echo=T, eval=T, message=F}
# X1 -> Y2 -> Y3 -> Y.final
0.3*0.1*0.1

# X1 -> Y2 -> Y.final
0.3*0.8

# X1 -> Y3 -> Y.final
0.15*0.1

# Total CDE of X1 on Y4
0.3*0.1*0.1 + 0.3*0.8 + 0.15*0.1

```
:::

3. Indicate which causal paths there are from $X_{2}$ to $Y_{4}$ and that do not go through later exposures. Based on the population parameter values in the R code to generate the data, compute what the true controlled direct effect is of $X_{2}$ on $Y_{4}$.

::: {.callout-note collapse="true" icon=false}
### Answer 3: True CDE $X_{2} \rightarrow Y_{4}$

```{r CDE2-population, echo=T, eval=T, message=F}
# X2 -> Y3 -> Y.final
0.3*0.1

# X2 -> Y.final
0.15

# Total CDE of X2 on Y4
0.3*0.1 + 0.15

```
:::

4. Indicate which causal paths there are from $X_{3}$ to $Y_{4}$ and that do not go through later exposures. Based on the population parameter values in the R code to generate the data, compute what the true controlled direct effect is of $X_{3}$ on $Y_{4}$. 


::: {.callout-note collapse="true" icon=false}
### Answer 4: True CDE $X_{3} \rightarrow Y_{4}$

```{r CDE3-population, echo=T, eval=T, message=F}
# X3 -> Y.final
0.3

# Total CDE X3 on Y4
0.3
```
:::

## Standard linear regression

We want to estimate the effect of exposure over occasions 1 to 3 on an end-of-study outcome $Y_{4}$. The previous measures of $Y$ can be regarded as time-varying covariates. 

5. For $Y_{1}$, $Y_{2}$, and $Y_{3}$, discuss whether one should control for them, or not. 

::: {.callout-note collapse="true" icon=false}
### Answer 5
Variable $Y_{1}$ is only a confounder between exposure and the outcome; hence, we should control for it. 

The variable $Y_{2}$ has two roles in the causal structure. It is a *confounder* of the relation between $X_{3}$ and $Y_{4}$: $X_{3} \leftarrow Y_{2} \rightarrow Y_{3} \rightarrow Y_{4}$. This would imply we should control for it to avoid confounder bias. It is also a mediator for the effect of $X_{1}$ on $Y_{4}$: $X_{1} \rightarrow Y_{2} \rightarrow Y_{3} \rightarrow Y_{4}$ and $X_{1} \rightarrow Y_{2} \rightarrow X_{3} \rightarrow Y_{4}$. This would imply we should *not* control for it, to avoid overcontrol bias (that is, bias that arises when we block an indirect path from the cause to the effect). Controlling for $Y_{2}$ would remove part of the total causal effect $X_{1}$ has on $Y_{4}$. This is a catch-22.

The variable $Y_{3}$ is only a mediator in this model: $X_{1} \rightarrow Y_{2} \rightarrow Y_{3} \rightarrow Y_{4}$; $X_{1} \rightarrow X_2 \rightarrow Y_{3} \rightarrow Y_{4}$; $X_{1} \rightarrow Y_{3} \rightarrow Y_{4}$; $X_{2} \rightarrow Y_{3} \rightarrow Y_{4}$. So, including $Y_{3}$ as a covariate will lead to overcontrol bias in estimating the controlled direct effects of $X_{1}$ and $X_{2}$. 
:::

6. Before we consider a more sophisticated approach to this problem, we begin with considering two simpler models. Each of these is associated with a specific form of bias in estimating the causal effect of the time-varying exposure on $Y_{4}$. Run a regression model with the time-varying covariates included. 

::: {.callout-note collapse="true" icon=false}
### Answer 6: Standard regression 1

```{r glm1, echo=T, eval=T, message=F}
out1 <- glm(final.Y ~ C + X1 + X2 + X3 + Y1 + Y2 + Y3, data=data)
summary(out1)
```

In this model, we have the problem of over control bias due to controlling for mediators $Y_{2}$ and $Y_{3}$, which blocks  causal paths from the time-varying exposure to the outcome.
:::
 
7. Run a regression model without the time-varying covariates.

::: {.callout-note collapse="true" icon=false}
### Answer 7: Standard regression 2
```{r glm2, echo=T, eval=T, message=F}
out2 <- glm(final.Y ~ C + X1 + X2 + X3 + Y1, data=data)
summary(out2)
```

This model results in confounder bias because it fails to control for confounders $Y_{1}$ and $Y_{2}$. Note that $Y_{3}$ is not a counfounder in this model, so omitting it is not associated with confounder bias.
:::

8. Compare the results of these two models. 

::: {.callout-note collapse="true" icon=false}
### Answer 8: Standard regression comparison

The results for the effect of $X_1$ to $X_3$ on $Y_{4}$ are quite different across these two models, and they also deviate from the actual effects that we computed based on the truth above:

| Exposure | Model 1 | Model 2 | Truth |
|----------|:-----:|:------:|:------:|
| $X_{1}$ | -0.00 | 0.22 | 0.258 |
| $X_{2}$ | 0.15  | 0.14 |  0.180 |
| $X_{3}$ | 0.30 | 0.46 | 0.300 |

We know that neither model is correct: Model 1 blocks causal paths through $Y_2$ and $Y_3$ (overcontrol bias), while model 2 fails to account for confounding due to $Y_1$ and $Y_2$.
:::

## IPW estimation

9. We will now use the marginal structural model as described by @vanderweele_causal_2016. First, compute the propensity score (i.e., the probability of receiving exposure) at wave 1, wave 2, and 3 *using logistic regression*. For each of these, you should include all prior versions of $X$ and the covariate $Y$, and all time-invariant (or baseline) covariates (here $C$). 

::: {.callout-note collapse="true" icon=false}
### Answer 9: Propensity scores using logistic regression

```{r PSs, echo=T, eval=T, message=F}
# Compute the propensity scores at wave 1 
res.X1 <- glm(X1 ~  C, family = binomial(), data = data)
ps1 <- predict(res.X1, type = "response")
data$ps1 <- ps1

# Compute the propensity scores at wave 2 
res.X2 <- glm(X2 ~  C + X1 + Y1, family = binomial(), data = data)
ps2 <- predict(res.X2, type = "response")
data$ps2 <- ps2

# Compute the propensity scores at wave 3 
res.X3 <- glm(X3 ~ C + X1 + X2 + Y1 + Y2, family = binomial(), data = data)
ps3 <- predict(res.X3, type = "response")
data$ps3 <- ps3
```

:::

10. Note that strictly speaking, for this particular model (as shown in the DAG), we would not need to include C to estimate the propensity scores at wave 2 and wave 3. Explain why not, and whether it matters that we include it here.

::: {.callout-note collapse="true" icon=false}
### Answer 10

$C$ only has direct effects on X1 and Y1; since both are included as predictors for the propensity scores at wave 2 and wave 3, the effect of $C$ is already controlled for then. However, it does not create a problem to include it; it does not block a indirect path that we would want to remain open (i.e., it is not a mediator), nor does it open a path that should remain closed (i.e., it is not a collider). Including or not including it for `ps2` and `ps3` does not make a difference.
:::

11. Make histograms for the propensity scores of the treated and the untreated at wave 2 and wave 3. What does this show? 

::: {.callout-note collapse="true" icon=false}
### Answer 11

```{r PSs-histogram, echo=T, eval=T, message=F}
# Plot the propensity scores at each wave
M<-matrix(c(1:3),1,3, byrow = FALSE)
layout(M)

for (t in 1:3)
{	k <- subset(data, select = c(paste0("X", t)))
	data.1 <- data[ which(k == 1), ]
	data.0 <- data[ which(k == 0), ]
	ps.t.1 <- subset(data.1, select = c(paste0("ps", t)))
	ps.t.0 <- subset(data.0, select = c(paste0("ps", t)))
	hist0 <- hist(as.numeric(ps.t.1[[1]]), breaks=30, plot=FALSE)
	hist1 <- hist(ps.t.0[[1]], breaks=30, plot=FALSE)
	title <- paste0("Propensity scores at wave ", t)
	plot( hist1, col=rgb(0,0,1,1/4), xlim=c(0,1), 
    		xlab="Propensity score", main=title)  
	plot( hist0, col=rgb(0,1,0,1/4), xlim=c(0,1), add=T) 
}
```

It shows that the distribution of the propensity scores for the treated and the untreated overlap well (assumption of positivity), at each occasion.
:::

12. Next, compute the *unstabilized* inverse probability weights at wave 1, 2, and 3. Recall that these are computed as
$$
W_{it} = X_{it} \frac{1}{P[X_{it} = 1 | \bar{L}_{it}, \bar{A}_{i,t - 1}]} + (1 - X_{it})\frac{1}{(1 - P[X_{it} = 1 | \bar{L}_{it}, \bar{A}_{i,t - 1}])}
$$ 
From these wave-specific weights, compute the overall weight, by taking the product of the wave-specific weights. 

::: {.callout-note collapse="true" icon=false}
### Answer 12: Compute weights

```{r IPW, echo=T, eval=T, message=F}
# Compute the inverse probability weights at waves 1, 2 and 3
data$ipw1 <- ifelse(data$X1==1, 1/data$ps1, 1/(1-data$ps1))
data$ipw2 <- ifelse(data$X2==1, 1/data$ps2, 1/(1-data$ps2))
data$ipw3 <- ifelse(data$X3==1, 1/data$ps3, 1/(1-data$ps3))

# Compute the total ipw
data$ipw.123 <- data$ipw1 * data$ipw2 * data$ipw3 
```

:::

13. Finally, we can run a regression model with $Y_{4}$ as the outcome variable, and $X_1$, $X_2$, $X_3$, and $Y_1$ as its predictors, using the total weights computed above.

::: {.callout-note collapse="true" icon=false}
### Answer 13: Effect estimation

```{r effect-estimation, echo=T, eval=T, message=F}
# Regression with inverse probability weighting with X1, X2, X3 and Y1 as its predictors
out3 <- glm(final.Y ~ X1 + X2 + X3 + Y1, 
		weights = ipw.123, data=data)

# Another regression with inverse probability weighting which now also includes the baseline confounder (just 
# for comparison)
out4 <- glm(final.Y ~ C + X1 + X2 + X3 + Y1, 
		weights = ipw.123, data=data)

# Another regression with inverse probability weighting which includes C but not Y1
out5 <- glm(final.Y ~ C + X1 + X2 + X3, 
		weights = ipw.123, data=data)

summary(out3)
summary(out4)
summary(out5)
```

It shows that whether the baseline covariate $C$ is included or not, makes no difference. This is because it has already been accounted for when computing the inverse probability weights. Furthermore, when considering the parameter estimates here it can be seen these are in fact very close to the true effects, which were computed at the start based on the parameter values that were used to simulate the data (i.e., the Truth).
:::


## Conclusion

14. Compare the results from the marginal structural model to the results from the other two models. What does this show you?

::: {.callout-note collapse="true" icon=false}
### Answer 14: Conclusion

| Exposure | Model 1 | Model 2 | Model 3 | Truth |
|----------|:-------:|:-------:|:-------:|:-----:|
| $X_{1}$ | -0.00 | 0.22 | 0.26 | 0.258 |
| $X_{2}$ | 0.15  | 0.14 | 0.18 |  0.180 |
| $X_{3}$ | 0.30 | 0.46 | 0.30 | 0.300 |

Model 1 includes $Y_2$ and $Y_3$ as a covariate, and thus leads to overcontrol bias when estimating the effects of $X_1$ and $X_2$. It only shows the direct effects of the time-varying exposure, not the indirect effects.

Model 2 does not include $Y_2$ and $Y_3$ in any manner. Therefore, this model leads to confounder bias, since $Y_2$ is a confounder for the $X_3 \rightarrow Y_{4}$ relation.

Model 3 is used to account for confounders, without blocking indirect paths. Hence, it should inform us on the joint exposure effect of the time-varying exposure. Its estimates are very close to the true values (based on the model parameters that we  used to simulated the data with).
:::

Why IPW estimation of an MSM works, and how it accounts for time-dependent confounding without blocking the relevant mediation paths, is not easy to see, or to even get some intuition for. But recall that in week 2 we learned that by using IPW, we create a balanced sample (also sometimes referred to as a *pseudo population*) that, within a certain level of the confounder, has an equal number of individuals in each exposure group. That implied that in this balance sample, we have $P[X_{it} = 1] = 0.5$ for everyone. This balancing property of IPW is therefore a way to mimic an RCT. Balancing thus removes the arrows that point into the exposure nodes (again, as would be the case in an RCT).   

## Some useful R packages
For these exercises we have made use of base R functions. This is helpful to get a better understanding of how IPW estimation actually works. However, there exist many useful packages that can help with assessing covariate (im)balance, and with creating inverse probability weights. I highly recommend the packages `cobalt` and `WeightIt` by Noah Greifer, as they have excellent documentation online that can help you use more advanced IPW-related techniques. You might consider using these packages for assignment 2. 

