---
title: "Lab Exercises"
subtitle: "Week 3: Rubin Causal Model (Part I)"
author: 
- Ellen L. Hamaker
- Jeroen D. Mulder
editor: source
bibliography: references.bib
---

In these exercises, we follow the analyses discussed in @schafer_average_2008, focusing on Methods 1 to 3. We will also use the data from @schafer_average_2008, which are in a data file called `SchaferKangData.dat`. These are simulated data, and hence the authors (and we) know what the correct answer to the question "What is the effect of dieting on emotional distress?" actually is. Hence, the purpose of the exercises here is to obtain a deeper understanding and hands-on experience with the diverse techniques.

Make sure to compare the results you get throughout the exercises to those reported in Table 6 of @schafer_average_2008. For null-hypothesis tests, you can use a significance level of 0.05 throughout.

## Setup
In this practical you will make use of various R packages. If you havenâ€™t already, install the packages `tableone` using `install.packages("tableone")`. 

Load the data, which are in the data file called `SchaferKangData.dat`. Take a look at the data set. See Table 3 in @schafer_average_2008 for a description of the variables.

```{r setup, eval = FALSE}
df <- read.table("SchaferKangData.dat", header = TRUE)
head(df, n = 10)
```


## Method 1: Compare Means
When a randomized controlled trial (RCT) has been conducted, the treatment groups should not differ on any (pre-treatment) covariate due to random assignment. In that case, the ACE can be computed by taking the difference in means between the two groups for the outcome variable. This is also referred to as the *prima facie* effect. Although the current data are not generated by a RCT scenario, we will nevertheless consider this naive estimation approach for the causal effect.

::: {.callout-note icon=false collapse=true}

## Compare the means between the groups on the outcome variable. Use, for instance `t.test()` in R.

You can perform a two-sample t-test using the R code below:

```{r t-test, eval = FALSE}
t.test(DISTR.2 ~ DIET, data = df)

```

The mean difference is the *prima facie* estimate of the average causal effect of dieting on distress. The results indicate that the average of the girls who did diet is $0.703 - 0.645= 0.059$ higher than the average of the girls who did not diet, $t = -3.886$, $SE = 0.015$. This difference is statistically significant, $p < .001$. 
:::

## Investigating Covariate Imbalance
The mean difference above is based on the assumption that there is no confounding. However, we have a set of observed covariates, and if our data mimic an RCT, there should be no mean differences between the two groups on these covariates. We check this with the standardized mean difference (rather than a t-test, because we do not want it to be dependent on sample size), that is $$\Delta Z = \frac{(\bar{Z} | X = 1) - (\bar{Z} | X = 0)}{\sqrt{((S^{2} | X = 1) +(S^{2} | X = 0)) / 2}},$$
where $\bar{Z} | X = x$ is the mean of covariate $Z$ in group $x$, $S^{2} | X = x$ is the variance in group $x$, and $X = 1$ is the diet group and $X = 0$ is the non-diet group. 



::: {.callout-note icon=false collapse=true}

## Determine the normalized difference between the girls who did diet versus the girls who did not diet on the first covariate, that is, `DISTR.1` (emotional distress at wave 1).

That can be done using the R code below:

```{r subset-DIET, eval = FALSE}
df1 <- df[ which(df$DIET == 1), ] # Select diet group
df0 <- df[ which(df$DIET == 0), ] # Select non-diet group

# Code the formula for SMD in R
( mean(df1$DISTR.1) - mean(df0$DISTR.1) ) / ( sqrt( (var(df1$DISTR.1) + var(df0$DISTR.1)) / 2))
```

The SMD with regards to the covariate `DISTR.1` is $0.214$. 
:::

Instead of computing these SMDs ourselves, we can also use the function `CreateTableOne()` from the R package `tableone`: 

```{r SMDs, eval = FALSE}
library(tableone) # Load the package

table1 <- CreateTableOne( # Create SMDs for all covariates
  vars = c("DISTR.1","BLACK", "NBHISP", "GRADE", "SLFHLTH", "SLFWGHT", 
           "WORKHARD", "GOODQUAL", "PHYSFIT", "PROUD", "LIKESLF", "ACCEPTED",
           "FEELLOVD"), 
  strata = "DIET", 
  data = df,
  test = FALSE
)
```


::: {.callout-note icon=false collapse=true}

## Obtain the table with standardize mean differences using `print(table1, smd = TRUE)`, and comment on wheter there is imbalance on the covariates across the groups. 

Running `print(table1, smd = TRUE)` gives:


```{r SMDs-result, eval = FALSE}
#                       Stratified by DIET
#                        0           1           SMD   
#   n                    4780        1220              
#   DISTR.1 (mean (SD))  0.62 (0.42) 0.71 (0.45)  0.214
#   BLACK (mean (SD))    0.26 (0.44) 0.17 (0.38)  0.197
#   NBHISP (mean (SD))   0.15 (0.35) 0.15 (0.36)  0.021
#   GRADE (mean (SD))    9.16 (1.39) 9.37 (1.34)  0.152
#   SLFHLTH (mean (SD))  2.20 (0.93) 2.35 (0.91)  0.171
#   SLFWGHT (mean (SD))  3.19 (0.76) 3.84 (0.70)  0.895
#   WORKHARD (mean (SD)) 2.14 (0.91) 2.05 (0.85)  0.093
#   GOODQUAL (mean (SD)) 1.80 (0.67) 1.84 (0.71)  0.055
#   PHYSFIT (mean (SD))  2.24 (0.93) 2.53 (0.93)  0.320
#   PROUD (mean (SD))    1.76 (0.77) 1.86 (0.79)  0.126
#   LIKESLF (mean (SD))  2.09 (0.99) 2.52 (1.06)  0.420
#   ACCEPTED (mean (SD)) 2.14 (1.00) 2.35 (1.06)  0.207
#   FEELLOVD (mean (SD)) 1.78 (0.83) 1.93 (0.90)  0.172
```

Most of the SMDs (the last column) are larger than the rule of thumb of 0.1. This implies that there is considerable imbalance across the two groups with respect to these covariates. This means the data do not mimic an RCT very well. Hence, some action to tackle this is required.
:::

## Method 2: ANCOVA
Method 2 of @schafer_average_2008 is based on including possible confounders as covariates (or predictors) in a model for the outcome: When there are no interactions between predictors in the model they refer to the analysis as ANCOVA, with interactions between predictors it is more generally referred to as "regression". We will include all the covariates in our analyses below, even when they have a small standardized mean difference. In the latter case there may not be a need to correct for differences in them between the groups, but they may still account for variance in the outcome variable, and by accounting for this, we increase the power of our analysis.

To run an ANCOVA, we can simply run a regression model without interactions between the predictors. Our model here can be written as: 
$$
\begin{align}DISTR.2 = &\alpha + \theta DIET + \\
&\beta_{1} DISTR.1 + \beta_{2} BLACK + \beta_{3} NBHISP + \beta_{4} GRADE + \beta_{5} SLFHLTH + \\
&\beta _{6} SLFWGHT + \beta_{7} WORKSHARD + \beta_{8} GOODQUAL + \beta_{9} PHYSFIT + \\
&\beta_{10} PROUD + \beta_{11} LIKESLF + \beta_{12} ACCEPTED + \beta_{13} FEELLOVED
\end{align}
$$
Note, since the categorical variables $DIET$, $BLACK$ and $NBHISP$ are dummy variables (they only have 2 categories), you do not need to treat them differently than the continuous covariates.

::: {.callout-note icon=false collapse=true}

## Run the ANCOVA model (for instance using the function `glm()` in R), and interpret the results.


```{r ANCOVA, eval = FALSE}
mod_ANCOVA <- glm(
  formula = DISTR.2 ~ DIET + DISTR.1 + BLACK + NBHISP + GRADE + SLFHLTH + 
    SLFWGHT + WORKHARD + GOODQUAL + PHYSFIT + PROUD + LIKESLF + ACCEPTED + 
    FEELLOVD,
  data = df
)

summary(mod_ANCOVA)
```

The results indicate that after correcting for the effect of the covariates, the effect of the treatment (i.e., `DIET`) on the outcome (i.e. `DISTR.2`) is not significant; the parameter estimate of the ACE is $-0.014$, $SE = 0.013$, $t = -1.057$, $p = .291$.
:::

We can extend the ANCOVA model above by incorporating product terms between the predictors:

- product between covariate and itself: quadratic effect
- product between two covariates: interaction
- product between treatment and covariates: non-parallel planes, see Figure 2 in @schafer_average_2008. 

We will not proceed with this here---note that @schafer_average_2008 consider the latter option in their paper---but two additional comments are in place:

- Adding such product terms quickly increases the number of parameters that we need to estimate; this reduces the power (especially relevant when dealing with small sample sizes).
- Before including interactions, one needs to center the covariates, and the interaction terms then needs to be centered again; failing to do so implies the main effect for treatment may not represent the average causal effect of treatment.

## Method 3: Regression Estimation

Regression estimation is not the same as regression analysis (which was discussed above). In regression estimation, we make actual predictions of the potential outcomes that were not observed, and use these to compute the causal effect of interest.

To use regression estimation, you have to:

1. Divide the data set into those who were treated and those who were not treated. 
2. Estimate a regression model (with all the covariates) in each group separately. 
3. Obtain the parameter estimates from each group; see Equations (13) and (14) in @schafer_average_2008. 
4. Use these, and the covariates to predict the potential outcomes $\hat{Y}^{0$ and $\hat{Y}^1$ for each person. 
5. Compute the average difference between these predicted potential outcomes. 

Hence, this approach is a technique to impute the missing values in the data file that only contains the potential outcomes that were observed. As this is a somewhat more challenging approach, some of the code will be presented immediately, so that you can work from there to answer the questions.

We start with creating separate data sets for the two treatment groups, and running a regression analysis for each group separately:

```{r method3-subset, eval = FALSE}
# Subset the data
df1 <- subset(df, DIET==1) # Diet group
df0 <- subset(df, DIET==0) # Non-diet group

# Regression analysis with only people with X = 1
mod_diet <- glm(
  formula = DISTR.2 ~ + DISTR.1 + as.factor(BLACK) + as.factor(NBHISP) + GRADE + 
    SLFHLTH + SLFWGHT + WORKHARD + GOODQUAL + PHYSFIT + PROUD + LIKESLF + 
    ACCEPTED + FEELLOVD,
  data = df1
)

# Regression analysis with only people with X = 0
mod_nondiet <- glm(
  formula = DISTR.2 ~ + DISTR.1 + as.factor(BLACK) + as.factor(NBHISP) + GRADE + 
    SLFHLTH + SLFWGHT + WORKHARD + GOODQUAL + PHYSFIT + PROUD + LIKESLF + 
    ACCEPTED + FEELLOVD,
  data = df0
)

```

Now we can obtain estimates for everyone (whether we observed $X=1$ or $X=0$) for the potential outcome under treatment $Y^1$ and under no treatment $Y^1$:

```{r method3-predict, eval = FALSE}
# Predict outcome for all cases using parameter estimates based on only diet group
preds_Y1 <- predict(mod_diet, newdata = df)

# Predict outcome for all cases using parameter estimates based on only non-diet group
preds_Y0 <- predict(mod_nondiet, newdata = df)
```

::: {.callout-note icon=false collapse=true}

## How can the results be used to estimate the ACE?

We now have predicted potential outcomes for everyone, and can use a t-test to compare these. 

```{r predicted-POs, eval = FALSE}
# Inspect predicted potential outcomes
dbind(preds_Y0, preds_Y1)[1:10, ]

# Estimate the causal effect using a paired t-test
t.test(preds_Y0, preds_Y1, paired = TRUE, alternative = "two.sided")
```

Although in reality we can only ever observe one potential outcome per person, with this technique we obtained an estimate for each person's potential outcome under treatment ($X=1$) and under no treatment ($X=0$). We can now use these estimated potential outcomes to compute the ACE by taking the mean difference.

It is important to realize the p-value that is obtained (and the standard error) are not correct. These are based on the assumption these are observed, rather than estimated scores.
:::

Above we have used the predicted potential outcomes for everyone. However, one of the potential outcomes is actually observed, and we could use that one instead of the predicted potential outcomes (i.e., we use the observed fact, and predict only the counterfact). Hence, for  individuals in the no treatment condition you use the observed outcome $Y$ rather than predicted the predicted counterfact $\hat{Y}^0$, and for those in the treatment condition you use the observed $Y$ instead of the predicted counterfact $\hat{Y}^1$. 

```{r method3b, eval = FALSE}
preds_Y0_onlyCounterfact <- preds_Y0 # Copy predicted potential outcomes
preds_Y0_onlyCounterfact[df$DIET==0] <- df$DISTR.2[df$DIET==0] # Replace observed potential outcomes with factual

preds_Y1_onlyCounterfact <- preds_Y1 # Copy predicted potential outcomes
preds_Y1_onlyCounterfact[df$DIET==1] <- df$DISTR.2[df$DIET==1] # Replace observed potential outcomes with factual
```



::: {.callout-note icon=false collapse=true}

## Check whether this leads to a different result.

Again, we can do a paired t-test, but now with the observed and predicted potential outcomes: 

```{r method3b-test, eval = FALSE}
t.test(
  x = preds_Y0_onlyCounterfact,
  y = preds_Y1_onlyCounterfact, 
  paired = TRUE, 
  alternative = "two.sided"
)
```

Although the predicted potential outcomes and the actual observed potential outcomes are not exactly the same, using only the predicted potential outcomes (like we did first), or using a combination of predicated and observed potential outcomes (as we did here), makes virtually no difference for the estimated causal effect.
:::

## Conclusion
In both Method 2 and 3 we have assumed linear relations between the covariates $Z$ and the outcome $Y$. This is a parametric assumption that we make in Phase III additional to the causal identification assumptions made in Phase II. 
